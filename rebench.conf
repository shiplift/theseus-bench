#ReBench -*- mode: yaml; yaml-indent-offset: 4 -*-

standard_experiment: MicroBenches
standard_data_file: 'output/current.tsv'

reporting:
    # results can also be reported to a codespeed instance
    # see: https://github.com/tobami/codespeed
    # codespeed:
    #     url: http://localhost:1/ # not supposed to work 
    #     # other details like commitid are required to be given as parameters
    confidence_level: 0.95

runs:
    number_of_data_points: 10

# settings for quick runs, useful for fast feedback during experiments
quick_runs:
    number_of_data_points: 3
    max_time: 15   # time in seconds

# definition of benchmark suites
benchmark_suites:
    MicroBenches:
        performance_reader: TestVMPerformance
        command: "%(benchmark)s %(input)s"
        input_sizes: [ 1000000,  2000000,  3000000,  4000000,  5000000,
                       6000000,  7000000,  8000000,  9000000, 10000000,
                      11000000, 12000000, 13000000, 14000000, 15000000,
                      16000000, 17000000, 18000000, 19000000, 20000000]
        benchmarks: &defaultbenchmarks
            - append
            # - arbitraty_precision_ints
            - filter
            - map
            # - tree
            - reverse
    NanoBenches:
        performance_reader: TestVMPerformance
        command: "%(benchmark)s 5000000"
        benchmarks:
            - append
            # - arbitraty_precision_ints
            - filter
            - map
            # - tree
            - reverse

    Exploration:
        performance_reader: TestVMPerformance
        command: -A-s -A%(input)s -A-w -A%(variable)s %(benchmark)s
        input_sizes: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,
                      18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,
                      33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
                      48, 49, 50, 51, 52, 53]
        variable_values: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,
                          17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
                          31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,
                          45, 46, 47, 48, 49, 50, 51, 52, 53]
        benchmarks:
             - append
             - arbitraty_precision_ints
             - filter
             - map
             - tree
             - reverse

virtual_machines:
    Lamb:
        path: compare/lamb
        binary: LAMB_C_RUN
    LambUncached:
        path: compare/lamb
        binary: LAMB_U_RUN
    OCaml:
        path: compare/ocaml
        binary: OCAML_RUN
    MLton:
        path: compare/sml
        binary: MLTON_RUN
    SMLNJ:
        path: compare/sml
        binary: SMLNJ_RUN
    Racket:
        path: compare/racket
        binary: RACKET_RUN
    Pycket:
        path: compare/racket
        binary: RACKET_RUN

experiments:
    MicroBenches:
        description: >
            Microbenchmarks on some functional languages
        benchmark: MicroBenches
        executions: &allvms
          - Lamb
          - LambUncached
          - Racket
          - Pycket
          - OCaml
          - SMLNJ
          - MLton
    NanoBenches:
        description: >
            More Microbenchmarks on some functional languages
        benchmark: MicroBenches
        executions: *allvms
    DoLambFast:
        description: Run all benchmarks fast with lamb
        number_of_data_points: 1
        benchmark: NanoBenches
        executions: LambUncached
        data_file: output/nevermind.data
    DoAllFast:
        description: Run all benchmarks fast with lamb
        number_of_data_points: 1
        benchmark: NanoBenches
        executions: *allvms
        data_file: output/nevermind.data
    Explore:
        description: Run all benchmarks fast with lamb
        number_of_data_points: 1
        benchmark: Exploration
        executions: LambUncached
        data_file: output/explore.tsv
# EOF
