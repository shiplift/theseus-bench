#ReBench -*- mode: yaml; yaml-indent-offset: 4 -*-

default_experiment: NanoBenches
default_data_file: 'output/current.tsv'

# reporting:
#     # results can also be reported to a codespeed instance
#     # see: https://github.com/tobami/codespeed
#     # codespeed:
#     #     url: http://localhost:1/ # not supposed to work
#     #     # other details like commitid are required to be given as parameters
#     confidence_level: 0.95

runs:
    invocations: 10

# definition of benchmark suites
benchmark_suites:
    MicroBenches:
        gauge_adapter: Multivariate
        command: "%(benchmark)s %(input)s"
        input_sizes: [ 1000000,  2000000,  3000000,  4000000,  5000000,
                       6000000,  7000000,  8000000,  9000000, 10000000,
                      11000000, 12000000, 13000000, 14000000, 15000000,
                      16000000, 17000000, 18000000, 19000000, 20000000]
        benchmarks: &defaultbenchmarks
            - append
            - appendn
            - filter
            - filtern
            - map
            - mapn
            - reverse
            - reversen
            - tree
            - treen
            # - arbitraty_precision_ints
    NanoBenches:
        gauge_adapter: Multivariate
        command: "%(benchmark)s"
        benchmarks:
            - append:
                extra_args: 20000000
            - appendn:
                extra_args: 20000000
            - filter:
                extra_args: 25000000
            - filtern:
                extra_args: 25000000
            - map:
                extra_args: 20000000
            - mapn:
                extra_args: 20000000
            - reverse:
                extra_args: 20000000
            - reversen:
                extra_args: 20000000
            - tree:
                extra_args: 18000000
            - treen:
                extra_args: 18000000
            # - arbitraty_precision_ints
    SqueakParadigmBenches:
        gauge_adapter: Multivariate
        command: "%(benchmark)s"
        benchmarks:
            - append:
                extra_args: 20000000
            - appendn:
                extra_args: 20000000
            - filter:
                extra_args: 25000000
            - filtern:
                extra_args: 25000000
            - map:
                extra_args: 20000000
            - mapn:
                extra_args: 20000000
            - reverse:
                extra_args: 20000000
            - reversen:
                extra_args: 20000000

    Exploration:
        gauge_adapter: Multivariate
        # lamb
        # command: "-A-s -A%(input)s -A-w -A%(variable)s -A-d -A%(cores)s %(benchmark)s"
        # pycket/rsqueak
        command: "-A--shapes-s -A%(input)s -A--shapes-w -A%(variable)s -A--shapes-d -A%(cores)s %(benchmark)s"
        # input_sizes: [3, 5, 13, 17, 21, 1023, 131071, 8388617]
        input_sizes: [17]
        #variable_values: [3, 5, 7, 8, 9, 10, 13, 15, 16, 21, 23]
        variable_values: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
        # abuse cores for shape depth
        cores: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
        #cores: [3, 5, 7, 8, 9, 10, 13, 15, 16, 21, 23]
        benchmarks: &explorationbenchmarks
            - append:
                extra_args: 40000000
            - appendn:
                extra_args: 30000000
            - filter:
                extra_args: 40000000
            - filtern:
                extra_args: 40000000
            - map:
                extra_args: 30000000
            - mapn:
                extra_args: 30000000
            - tree:
                extra_args: 18000000
            - treen:
                extra_args: 18000000
            - reverse:
                extra_args: 500000000
            - reversen:
                extra_args: 100000000


executors:
    Lamb:
        path: compare/lamb
        executable: LAMB_C_RUN
    LambNoopt:
        path: compare/lamb
        executable: LAMBNO_C_RUN
    LambUncached:
        path: compare/lamb
        executable: LAMB_U_RUN
    LambUncachedMulti:
        path: compare/lamb
        executable: LAMB_U_RUN
        execute_exclusively: false
    OCaml:
        path: compare/ocaml
        executable: OCAML_RUN
    MLton:
        path: compare/sml
        executable: MLTON_RUN
    SMLNJ:
        path: compare/sml
        executable: SMLNJ_RUN
    Racket:
        path: compare/racket
        executable: RACKET_RUN
    Pycket:
        path: compare/racket
        executable: PYCKET_RUN
    PycketOrig:
        path: compare/racket
        executable: PYCKET_ORIG_RUN
    PycketShapes:
        path: compare/racket
        executable: PYCKET_SHAPES_RUN
    PycketShapesMulti:
        path: compare/racket
        executable: PYCKET_SHAPES_RUN
        execute_exclusively: false
    Squeak:
        path: compare/squeak
        executable: SQUEAK_RUN
    RSqueakOrig:
        path: compare/squeak
        executable: RSQUEAK_ORIG_RUN
    RSqueakShapes:
        path: compare/squeak
        executable: RSQUEAK_SHAPES_RUN
    RSqueakShapesMulti:
        path: compare/squeak
        executable: RSQUEAK_SHAPES_RUN
        execute_exclusively: false
    SqueakFunctional:
        path: compare/squeak
        executable: SQUEAKF_RUN
    RSqueakFunctionalOrig:
        path: compare/squeak
        executable: RSQUEAKF_ORIG_RUN
    RSqueakFunctionalShapes:
        path: compare/squeak
        executable: RSQUEAKF_SHAPES_RUN
    Python:
        path: compare/python
        executable: PYTHON_RUN
    Pypy:
        path: compare/python
        executable: PYPY_RUN

experiments:
    MicroBenches:
        description: >
            Microbenchmarks on some functional languages
        suites:
          - MicroBenches
        executions: &allvms
          - Lamb
          - LambNoopt
          # - LambUncached
          - Racket
          # - Pycket
          - PycketShapes
          - PycketOrig
          - RSqueakShapes
          - RSqueakOrig
          - Squeak
          - OCaml
          - SMLNJ
          - MLton
          - Python
          - Pypy
    NanoBenches:
        description: >
            More Microbenchmarks on some functional languages
        suites:
          - NanoBenches
        executions: &vms
          - Lamb
          # - LambUncached
          # - Pycket
          - PycketShapes
          - PycketOrig
          - Racket
          - OCaml
          # - SMLNJ
          # - MLton
          # - Python
          - Pypy
        data_file: output/current-report.tsv
    NanoBenchesAll:
        description: >
            More Microbenchmarks on some functional languages
        suites:
          - NanoBenches
        executions: *allvms
        data_file: output/nanobenches-all.tsv
    SqueakParadigm:
        description: >
            See the effect of non-TCO in Squeak
        suites:
          - SqueakParadigmBenches
        executions:
          - RSqueakShapes
          - RSqueakOrig
          - Squeak
          - RSqueakFunctionalShapes
          - RSqueakFunctionalOrig
          - SqueakFunctional
        data_file: output/squeakparadigmtest.tsv
    DoLambFast:
        description: Run all benchmarks fast with lamb
        invocations: 1
        suites:
          - NanoBenches
        executions:
          - LambUncached
        data_file: output/nevermind.data
    DoRSqueakFast:
        description: Run all benchmarks fast with lamb
        invocations: 1
        suites:
          - NanoBenches
        executions:
          - RSqueakOrig
        data_file: output/nevermind.data
    DoAllFast:
        description: Run all benchmarks fast with lamb
        invocations: 1
        suites:
          - NanoBenches
        # executions: *allvms
        executions: *vms
        data_file: output/all-fast.tsv
    DoAllAllFast:
        description: Run all benchmarks fast with lamb
        invocations: 1
        suites:
          - NanoBenches
        executions: *allvms
        # executions: *vms
        data_file: output/all-all-fast.tsv
    Explore:
        description: Run all benchmarks fast with lamb
        invocations: 1
        suites:
          - Exploration
        executions: 
          - LambUncachedMulti
        data_file: output/explore.tsv
    ExploreP:
        description: Run all benchmarks fast with lamb
        invocations: 1
        suites:
          - Exploration
        executions: 
          - PycketShapesMulti
        data_file: output/explore-p.tsv
    ExploreR:
        description: Run all benchmarks fast with lamb
        invocations: 1
        suites:
          - Exploration
        executions: 
          - RSqueakShapesMulti
        data_file: output/explore-r.tsv
# EOF
